**进程间通信——队列**

（multiprocess.Queue）

# 1、进程间通信

IPC(Inter-Process Communication)

进程之间的数据隔离问题

```
from multiprocessing import Process
def work():
  global n
  n = 0
  print('子进程',n)
if __name__ == '__main__':
  n = 100
  p = Process(target=work)
  p.start()
  print('主进程',n)
```

# 2、队列

## 1）概念介绍

创建共享的进程队列，Queue是多进程安全的队列，可以使用Queue实现多进程之间的数据传递。

```
Queue([maxsize])
创建共享的进程队列。
参数 ：maxsize是队列中允许的最大项数。如果省略此参数，则无大小限制。
底层队列使用管道和锁定实现。
```

### 队列方法介绍

- Queue([maxsize])

- 创建共享的进程队列。maxsize是队列中允许的最大项数。如果省略此参数，则无大小限制。

底层队列使用管道和锁定实现。另外，还需要运行支持线程以便队列中的数据传输到底层管道中。

- Queue的实例q具有以下方法：

- q.get( [ block [ ,timeout ] ] )

- 返回q中的一个项目。如果q为空，此方法将阻塞，直到队列中有项目可用为止。block用于控

     制阻塞行为，默认为True. 如果设置为False，将引发Queue.Empty异常（定义在Queue模块中）。

    timeout是可选超时时间，用在阻塞模式中。如果在制定的时间间隔内没有项目变为可用，将引发Queue.Empty异常。

- q.get_nowait( )

            同q.get(False)方法。

- q.put(item [, block [,timeout ] ] )

将item放入队列。如果队列已满，此方法将阻塞至有空间可用为止。block控制阻塞行为，默

认为True。如果设置为False，将引发Queue.Empty异常（定义在Queue库模块中）。

timeout指定在阻塞模式中等待可用空间的时间长短。超时后将引发Queue.Full异常。

- q.qsize()

返回队列中目前项目的正确数量。此函数的结果并不可靠，因为在返回结果和在稍后程序中使

用结果之间，队列中可能添加或删除了项目。在某些系统上，此方法可能引发

NotImplementedError异常。

- q.empty()

如果调用此方法时 q为空，返回True。如果其他进程或线程正在往队列中添加项目，结果是

不可靠的。也就是说，在返回和使用结果之间，队列中可能已经加入新的项目。

- q.full()

如果q已满，返回为True. 由于线程的存在，结果也可能是不可靠的（参考q.empty（）方法）。。

### 其他方法

- q.close()

关闭队列，防止队列中加入更多数据。调用此方法时，后台线程将继续写入那些已入队列但尚未写

入的数据，但将在此方法完成时马上关闭。如果q被垃圾收集，将自动调用此方法。关闭队列不会

在队列使用者中生成任何类型的数据结束信号或异常。例如，如果某个使用者正被阻塞在get（）

操作上，关闭生产者中的队列不会导致get（）方法返回错误。

- q.cancel_join_thread()

不会再进程退出时自动连接后台线程。这可以防止join_thread()方法阻塞。

- q.join_thread()

连接队列的后台线程。此方法用于在调用q.close()方法后，等待所有队列项被消耗。默认情况下，

此方法由不是q的原始创建者的所有进程调用。调用q.cancel_join_thread()方法可以禁止这种行为。

## 2）代码实例

```
from multiprocessing import Queue
q=Queue(3)
#put ,get ,put_nowait,get_nowait,full,empty
q.put(3)
q.put(3)
q.put(3)
# q.put(3)  # 如果队列已经满了，程序就会停在这里，等待数据被别人取走，再将数据放入队
列。
     # 如果队列中的数据一直不被取走，程序就会永远停在这里。
try:
  q.put_nowait(3) # 可以使用put_nowait，如果队列满了不会阻塞，但是会因为队列满了而
报错。
except: # 因此我们可以用一个try语句来处理这个错误。这样程序不会一直阻塞下去，但是会丢掉这
个消息。
  print('队列已经满了')
# 因此，我们再放入数据之前，可以先看一下队列的状态，如果已经满了，就不继续put了。
print(q.full()) #满了
print(q.get())
print(q.get())
print(q.get())
# print(q.get()) # 同put方法一样，如果队列已经空了，那么继续取就会出现阻塞。
try:
  q.get_nowait(3) # 可以使用get_nowait，如果队列满了不会阻塞，但是会因为没取到值而
报错。
except: # 因此我们可以用一个try语句来处理这个错误。这样程序不会一直阻塞下去。
  print('队列已经空了')
print(q.empty()) #空了
```

```
import time
from multiprocessing import Process, Queue
def f(q):
  q.put([time.asctime(), 'from earth', 'hello'])  #调用主函数中p进程传递过来的
进程参数 put函数为向队列中添加一条数据。
if __name__ == '__main__':
  q = Queue() #创建一个Queue对象
  p = Process(target=f, args=(q,)) #创建一个进程
  p.start()
  print(q.get())
  p.join()
```

```
import os
import time
import multiprocessing
# 向queue中输入数据的函数
def inputQ(queue):
  info = str(os.getpid()) + '(put):' + str(time.asctime())
  queue.put(info)
# 向queue中输出数据的函数
def outputQ(queue):
  info = queue.get()
  print ('%s%s\033[32m%s\033[0m'%(str(os.getpid()), '(get):',info))
# Main
if __name__ == '__main__':
  multiprocessing.freeze_support()
  # 解决在Windows下运行有可能崩溃
  record1 = []  # store input processes
  record2 = []  # store output processes
  queue = multiprocessing.Queue(3)
  # 输入进程
  for i in range(5):
    process = multiprocessing.Process(target=inputQ,args=(queue,))
    time.sleep(1)
    process.start()
    record1.append(process)
  # 输出进程
  for i in range(5):
    process = multiprocessing.Process(target=outputQ,args=(queue,))
    process.start()
    record2.append(process)
  for p in record1:
    p.join()
  for p in record2:
    p.join()
```

## 3）生产者消费者模型

在并发编程中使用生产者和消费者模式能够解决绝大多数并发问题。该模式通过平衡生产线程和消费线

程的工作能力来提高程序的整体处理数据的速度。

#### 为什么要使用生产者和消费者模式

在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发当中，如果生

产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数

据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。为了解决这个问

题于是引入了生产者和消费者模式。

#### 什么是生产者消费者模式

生产者消费者模式是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直

接通讯，而通过阻塞队列来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞

队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生

产者和消费者的处理能力。

```
from multiprocessing import Process,Queue
import time,random,os
def consumer(q):
  while True:
    res=q.get()
    time.sleep(random.randint(1,3))
    print('%s 吃 %s' %(os.getpid(),res))
def producer(q):
  for i in range(10):
    time.sleep(random.randint(1,3))
    res='包子%s' %i
    q.put(res)
    print('%s 生产了 %s' %(os.getpid(),res))
if __name__ == '__main__':
  q=Queue()
  #生产者们:即厨师们
  p1=Process(target=producer,args=(q,))
  #消费者们:即吃货们
  c1=Process(target=consumer,args=(q,))
  #开始
  p1.start()
  c1.start()
  print('主')
```

消费者c在取空了q之后，则一直处于死循环中且卡在q.get()这一步。

生产者在生产完毕后，往队列中再发一个结束信号，这样消费者在接收到结束信号后就可以break出死循环。

```
from multiprocessing import Process,Queue
import time,random,os
def consumer(q):
  while True:
    res=q.get()
    if res is None:break #收到结束信号则结束
    time.sleep(random.randint(1,3))
    print('%s 吃 %s' %(os.getpid(),res))
def producer(q):
  for i in range(10):
    time.sleep(random.randint(1,3))
    res='包子%s' %i
    q.put(res)
    print('%s 生产了 %s' %(os.getpid(),res))
  q.put(None) #发送结束信号
if __name__ == '__main__':
  q=Queue()
  #生产者们:即厨师们
  p1=Process(target=producer,args=(q,))
  #消费者们:即吃货们
  c1=Process(target=consumer,args=(q,))
  #开始
  p1.start()
  c1.start()
  print('主')
```

结束信号None，不一定要由生产者发，主进程里同样可以发，但主进程需要等生产者结束后才应该发送该信号

```
from multiprocessing import Process,Queue
import time,random,os
def consumer(q):
  while True:
    res=q.get()
    if res is None:break #收到结束信号则结束
    time.sleep(random.randint(1,3))
    print('%s 吃 %s' %(os.getpid(),res))
def producer(q):
  for i in range(2):
    time.sleep(random.randint(1,3))
    res='包子%s' %i
    q.put(res)
    print('%s 生产了 %s' %(os.getpid(),res))
if __name__ == '__main__':
  q=Queue()
  #生产者们:即厨师们
  p1=Process(target=producer,args=(q,))
  #消费者们:即吃货们
  c1=Process(target=consumer,args=(q,))
  #开始
  p1.start()
  c1.start()
  p1.join()
  q.put(None) #发送结束信号
  print('主')
```

有多个生产者和多个消费者时有几个消费者就需要发送几次结束信号

```
from multiprocessing import Process,Queue
import time,random,os
def consumer(q):
  while True:
    res=q.get()
    if res is None:break #收到结束信号则结束
    time.sleep(random.randint(1,3))
    print('%s 吃 %s' %(os.getpid(),res))
def producer(name,q):
  for i in range(2):
    time.sleep(random.randint(1,3))
    res='%s%s' %(name,i)
    q.put(res)
    print('%s 生产了 %s' %(os.getpid(),res))
if __name__ == '__main__':
  q=Queue()
  #生产者们:即厨师们
  p1=Process(target=producer,args=('包子',q))
  p2=Process(target=producer,args=('骨头',q))
  p3=Process(target=producer,args=('泔水',q))
  #消费者们:即吃货们
  c1=Process(target=consumer,args=(q,))
  c2=Process(target=consumer,args=(q,))
  #开始
  p1.start()
  p2.start()
  p3.start()
  c1.start()
  p1.join() #必须保证生产者全部生产完毕,才应该发送结束信号
  p2.join()
  p3.join()
  q.put(None) #有几个消费者就应该发送几次结束信号None
  q.put(None) #发送结束信号
  print('主')
```

JoinableQueue([maxsize])

创建可连接的共享进程队列。这就像是一个Queue对象，但队列允许项目的使用者通知生产者项目已经

被成功处理。通知进程是使用共享的信号和条件变量来实现的。

- q.task_done()

使用者使用此方法发出信号，表示q.get()返回的项目已经被处理。如果调用此方法的次数大于从队

列中删除的项目数量，将引发ValueError异常。

- q.join()

生产者将使用此方法进行阻塞，直到队列中所有项目均被处理。阻塞将持续到为队列中的每个项目

均调用q.task_done()方法为止。

```
from multiprocessing import Process, JoinableQueue
import time, random, os
def consumer(q):
  while True:
    res = q.get()
    time.sleep(random.randint(1, 3))
    print('%s 吃 %s' % (os.getpid(), res))
    q.task_done()  # 向q.join()发送一次信号,证明一个数据已经被取走了
def producer(name, q):
  for i in range(10):
    time.sleep(random.randint(1, 3))
    res = '%s%s' % (name, i)
    q.put(res)
    print('%s 生产了 %s' % (os.getpid(), res))
  q.join()  # 生产完毕，使用此方法进行阻塞，直到队列中所有项目均被处理。
if __name__ == '__main__':
  q = JoinableQueue()
  # 生产者们:即厨师们
  p1 = Process(target=producer, args=('包子', q))
  p2 = Process(target=producer, args=('骨头', q))
  p3 = Process(target=producer, args=('泔水', q))
  # 消费者们:即吃货们
  c1 = Process(target=consumer, args=(q,))
  c2 = Process(target=consumer, args=(q,))
  c1.daemon = True
  c2.daemon = True
  # 开始
  p_l = [p1, p2, p3, c1, c2]
  for p in p_l:
    p.start()
  p1.join()
  p2.join()
  p3.join()
  print('主')
  # 主进程等--->p1,p2,p3等---->c1,c2
  # p1,p2,p3结束了,证明c1,c2肯定全都收完了p1,p2,p3发到队列的数据
  # 因而c1,c2也没有存在的价值了,不需要继续阻塞在进程中影响主进程了。应该随着主进程的结
    束而结束,所以设置成守护进程就可以了。
```